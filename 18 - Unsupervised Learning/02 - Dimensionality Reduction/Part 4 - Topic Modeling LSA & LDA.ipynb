{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b563ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/habibmudafiq/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/habibmudafiq/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "sw_indo = stopwords.words('indonesian') + list(punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b80eff",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "013b8166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ginandjar Tetap Ditahan. Jaksa Agung Dilaporka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jakarta Dikangkangi Para Preman\\nKALAU tak pun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Penyimpangan di Setpres Seolah Terjadi Sekaran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dibayarkan, Rapel Kenaikan Gaji Pegawai Pos\\nK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Kekerasan, Elite agar Duduk Bersama\\nSeju...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                teks\n",
       "0  Ginandjar Tetap Ditahan. Jaksa Agung Dilaporka...\n",
       "1  Jakarta Dikangkangi Para Preman\\nKALAU tak pun...\n",
       "2  Penyimpangan di Setpres Seolah Terjadi Sekaran...\n",
       "3  Dibayarkan, Rapel Kenaikan Gaji Pegawai Pos\\nK...\n",
       "4  Stop Kekerasan, Elite agar Duduk Bersama\\nSeju..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/kompas.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9efe19",
   "metadata": {},
   "source": [
    "# Extract BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fc9f83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11db58f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/jcop_usl/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "bow = CountVectorizer(\n",
    "    ngram_range=(1, 2),\n",
    "    tokenizer=word_tokenize,\n",
    "    stop_words=sw_indo,\n",
    "    min_df=5\n",
    ")\n",
    "\n",
    "bow_matrix = bow.fit_transform(df.teks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3dd4b2",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81f2fad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/jcop_usl/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "vocab = bow.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3189f609",
   "metadata": {},
   "source": [
    "# LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b3f4211",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c49d121",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa = TruncatedSVD(n_components=10, n_iter=10, random_state=42)\n",
    "lsa_matrix = lsa.fit_transform(bow_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce82a9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic(model):\n",
    "    return [\n",
    "        [vocab[idx] for idx in reversed(comp.argsort()[-6:]) if vocab[idx].isalnum()]\n",
    "        for comp in model.components_]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f3fc5ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['presiden', 'indonesia', 'pemerintah', 'dpr'],\n",
       " ['presiden', 'dpr', 'ketua', 'partai', 'mpr', 'tandjung'],\n",
       " ['pemerintah', 'rp', 'indonesia', 'bank', 'persen', 'utang'],\n",
       " ['rp', 'tandjung', 'dana', 'bulog', 'hukum', 'harga'],\n",
       " ['presiden', 'air', 'banjir', 'harga', 'rp', 'dpr'],\n",
       " ['harga', 'beras', 'rp', 'bbm'],\n",
       " ['mpr', 'konstitusi', 'bppn', 'uud'],\n",
       " ['indonesia', 'mpr', 'konstitusi', 'uud', 'perubahan', '1945'],\n",
       " ['pemerintah', 'dpr', 'israel', 'bppn', 'kota', 'aceh'],\n",
       " ['massa', 'rupiah', 'bunga', 'mpr', 'bank', 'suku']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_topic(lsa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c023491",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "055c3f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233a6723",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=10, max_iter=10, random_state=42)\n",
    "lda_matrix = lsa.fit_transform(bow_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f5dbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_topic(lda)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jcop_usl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
